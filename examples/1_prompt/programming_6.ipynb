{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggTblaACJYt"
      },
      "source": [
        "## Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3hdLh-hCJYu",
        "outputId": "a0e7cb30-07a7-4522-91dc-af1d1d9206fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/468.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/468.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install langchain_huggingface\n",
        "%pip install --upgrade --quiet huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXEm4a7WCJYw"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT-C_l0ZC86w",
        "outputId": "1353d687-c5b4-4a8e-b566-bd75ea7b3935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: \n",
            "Reasoning:  \n",
            "Check all pairwise products:  \n",
            "10 × 7 = 70 (Not 20)  \n",
            "10 × 13 = 130 (Not 20)  \n",
            "10 × 5 = 50 (Not 20)  \n",
            "10 × 3 = 30 (Not 20)  \n",
            "7 × 13 = 91 (Not 20)  \n",
            "7 × 5 = 35 (Not 20)  \n",
            "7 × 3 = 21 (Not 20)  \n",
            "13 × 5 = 65 (Not 20)  \n",
            "13 × 3 = 39 (Not 20)  \n",
            "5 × 3 = 15 (Not 20)  \n",
            "None of the pairwise products equal 20.  \n",
            "Answer: False.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your-key-here\"\n",
        "HUGGINGFACEHUB_API_TOKEN=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
        "\n",
        "#promp_template = \"descrivi l'italia\"\n",
        "\n",
        "prompt = \"\"\"Determine whether a number is the product of any two numbers in a given list.\n",
        "\n",
        "These are some examples of how to perform the task:\n",
        "\n",
        "Task: Is 15 the product of any two numbers in the list [4, 8, 9, 12, 2]?\n",
        "Reasoning:\n",
        "Check all pairwise products:\n",
        "4 x 8 = 32 (Not 15)\n",
        "4 x 9 = 36 (Not 15)\n",
        "4 x 12 = 48 (Not 15)\n",
        "4 x 2 = 8 (Not 15)\n",
        "8 x 9 = 72 (Not 15)\n",
        "8 x 12 = 96 (Not 15)\n",
        "8 x 2 = 16 (Not 15)\n",
        "9 x 12 = 108 (Not 15)\n",
        "9 x 2 = 18 (Not 15)\n",
        "12 x 2 = 24 (Not 15)\n",
        "None of the pairwise products equal 15.\n",
        "Answer: False.\n",
        "\n",
        "Task: Is 45 the product of any two numbers in the list [6, 4, 9, 2, 8]?\n",
        "Reasoning:\n",
        "Check all pairwise products:\n",
        "6 x 4 = 24 (Not 45)\n",
        "6 x 9 = 54 (Not 45)\n",
        "6 x 2 = 12 (Not 45)\n",
        "6 x 8 = 48 (Not 45)\n",
        "4 x 9 = 36 (Not 45)\n",
        "4 x 2 = 8 (Not 45)\n",
        "4 x 8 = 32 (Not 45)\n",
        "9 x 2 = 18 (Not 45)\n",
        "9 x 8 = 72 (Not 45)\n",
        "2 x 8 = 16 (Not 45)\n",
        "None of the pairwise products equal 45.\n",
        "Answer: False.\n",
        "\n",
        "Task: Is 72 the product of any two numbers in the list [6, 4, 9, 12, 2]?\n",
        "Reasoning:\n",
        "Check all pairwise products:\n",
        "6 x 4 = 24 (Not 72)\n",
        "6 x 9 = 54 (Not 72)\n",
        "6 x 12 = 72 (Matches!)\n",
        "A pair exists (6 x 12) that equals 72.\n",
        "Answer: True.\n",
        "\n",
        "Solve the following problem.\n",
        "Task: Is 20 the product of any two numbers in the list [10, 7, 13, 5, 3]?\n",
        "Answer: \"\"\"\n",
        "\n",
        "# Create ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    ('user', prompt)\n",
        "])\n",
        "\n",
        "\n",
        "model = HuggingFaceEndpoint(\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    temperature=0.5,\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
        ")\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Execute the prompt\n",
        "def ask_question():\n",
        "    # Set up the chain\n",
        "    chain = prompt_template | model | parser\n",
        "\n",
        "    # Execute the chain and return the result\n",
        "    response = chain.invoke({})\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        result = ask_question()\n",
        "        print(\"Result:\", result)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "agents",
      "language": "python",
      "name": "agents"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
